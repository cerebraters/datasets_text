{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cerebraters/datasets_text/blob/main/TESTpredict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzuz7rVU_Cfe",
        "outputId": "f2dbb81b-4841-4afc-e2c3-0dc1f5d273cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import joblib\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Dict, Any, Optional, Union, Tuple\n",
        "from functools import lru_cache\n",
        "import heapq\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "Xmw-eHTnZCQE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "5jm3R9G3ZGr2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemPredictor:\n",
        "    def __init__(self, min_cycles: int = 1, period_days: int = 30, top_k: int = 3,\n",
        "                 recent_weight: float = 2.0, decay_factor: float = 0.95,\n",
        "                 diversity_factor: float = 0.3, popularity_penalty: float = 0.7):\n",
        "        self.min_cycles = min_cycles\n",
        "        self.period_days = period_days\n",
        "        self.top_k = top_k\n",
        "        self.recent_weight = recent_weight\n",
        "        self.decay_factor = decay_factor\n",
        "        self.diversity_factor = diversity_factor\n",
        "        self.popularity_penalty = popularity_penalty\n",
        "        self.user_history = defaultdict(list)\n",
        "        self.global_item_freq = Counter()\n",
        "        self.global_top_items = []\n",
        "        self.update_counter = 0\n",
        "        self.max_history_size = 200\n",
        "        self.item_decay_rates = defaultdict(float)\n",
        "\n",
        "    def update_history(self, user_id: Union[str, int], item: str, purchase_date: datetime) -> None:\n",
        "        user_id = str(user_id)\n",
        "        self.user_history[user_id].append((item, purchase_date))\n",
        "        self.global_item_freq[item] += 1\n",
        "\n",
        "        # Apply decay to old frequencies\n",
        "        for item in list(self.global_item_freq.keys()):\n",
        "            self.global_item_freq[item] *= self.decay_factor\n",
        "\n",
        "        if len(self.user_history[user_id]) > self.max_history_size:\n",
        "            self.user_history[user_id] = sorted(\n",
        "                self.user_history[user_id][-self.max_history_size:],\n",
        "                key=lambda x: x[1], reverse=True\n",
        "            )\n",
        "\n",
        "        self.update_counter += 1\n",
        "        if self.update_counter % 50 == 0:\n",
        "            self.calculate_global_top_items()\n",
        "\n",
        "    def calculate_global_top_items(self) -> None:\n",
        "        if self.global_item_freq:\n",
        "            median_freq = np.median(list(self.global_item_freq.values()))\n",
        "            adaptive_min_cycles = max(1, int(median_freq * 0.3))\n",
        "\n",
        "            cyclic_items = {item: count for item, count in self.global_item_freq.items()\n",
        "                          if count >= adaptive_min_cycles}\n",
        "\n",
        "            if cyclic_items:\n",
        "                self.global_top_items = [item for item, _ in\n",
        "                                       Counter(cyclic_items).most_common(self.top_k*5)]\n",
        "            else:\n",
        "                self.global_top_items = []\n",
        "\n",
        "    def predict_for_user(self, user_id: Union[str, int], current_date: Optional[datetime] = None) -> List[str]:\n",
        "        current_date = current_date or datetime.now()\n",
        "        user_id = str(user_id)\n",
        "        predictions = []\n",
        "        user_items = Counter()\n",
        "\n",
        "        if user_id in self.user_history:\n",
        "            item_weights = defaultdict(float)\n",
        "            user_items = Counter(item for item, _ in self.user_history[user_id])\n",
        "\n",
        "            user_min_cycles = max(1, int(len(self.user_history[user_id]) * 0.1))\n",
        "            cyclic_items = {item for item, count in user_items.items()\n",
        "                           if count >= max(self.min_cycles, user_min_cycles)}\n",
        "\n",
        "            for item, purchase_date in sorted(self.user_history[user_id], key=lambda x: x[1], reverse=True):\n",
        "                if item not in cyclic_items:\n",
        "                    continue\n",
        "\n",
        "                days_ago = (current_date - purchase_date).days\n",
        "                if days_ago > self.period_days:\n",
        "                    continue\n",
        "\n",
        "                recency_weight = self.recent_weight if days_ago <= 7 else 1.0\n",
        "                frequency_weight = np.log1p(user_items[item])\n",
        "                decay_weight = self.decay_factor ** days_ago\n",
        "\n",
        "                # Apply popularity penalty for top global items\n",
        "                base_weight = recency_weight * frequency_weight * decay_weight\n",
        "                if item in self.global_top_items[:10]:\n",
        "                    base_weight *= self.popularity_penalty\n",
        "\n",
        "                item_weights[item] += base_weight * (1 + random.uniform(-self.diversity_factor, self.diversity_factor))\n",
        "\n",
        "            if item_weights:\n",
        "                predictions = [item for item, _ in sorted(\n",
        "                    item_weights.items(),\n",
        "                    key=lambda x: (-x[1], x[0])\n",
        "                )[:self.top_k*3]]\n",
        "\n",
        "        # Fallback with diversity\n",
        "        fallback_items = []\n",
        "        for item in self.global_top_items:\n",
        "            weight = user_items[item] * 2 if item in user_items else 1\n",
        "            if item in self.global_top_items[:10]:\n",
        "                weight *= 0.8  # Additional penalty for top global items\n",
        "            fallback_items.append((item, weight))\n",
        "\n",
        "        fallback_items = [item for item, _ in sorted(fallback_items, key=lambda x: -x[1])[:self.top_k*3]]\n",
        "\n",
        "        # Final selection with enforced diversity\n",
        "        all_candidates = list(set(predictions + fallback_items))\n",
        "        if len(all_candidates) >= 3:\n",
        "            # Select 1-2 personalized items and 1-2 diverse items\n",
        "            personalized = [i for i in predictions if i in user_items][:2]\n",
        "            diverse_pool = [i for i in all_candidates if i not in personalized]\n",
        "            diverse = random.sample(diverse_pool, min(len(diverse_pool), self.top_k - len(personalized)))\n",
        "            return personalized + diverse\n",
        "\n",
        "        return all_candidates[:self.top_k]\n"
      ],
      "metadata": {
        "id": "tZ_8PKSyZL14"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasketPredictor:\n",
        "    def __init__(self, min_samples: int = 1, top_k: int = 5, min_unique_checks: int = 1,\n",
        "                 diversity_factor: float = 0.3, place_diversity: float = 0.3):\n",
        "        self.min_samples = min_samples\n",
        "        self.top_k = top_k\n",
        "        self.min_unique_checks = min_unique_checks\n",
        "        self.diversity_factor = diversity_factor\n",
        "        self.place_diversity = place_diversity\n",
        "        self.item_encoder = LabelEncoder()\n",
        "        self.feature_encoder = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('customer', OneHotEncoder(handle_unknown='ignore'), ['customerId']),\n",
        "                ('place', OneHotEncoder(handle_unknown='ignore'), ['pointName']),\n",
        "                ('time', OneHotEncoder(handle_unknown='ignore'), ['day_of_week', 'month', 'time_of_day'])\n",
        "            ],\n",
        "            remainder='drop'\n",
        "        )\n",
        "        self.model = None\n",
        "        self.context_recommendations = defaultdict(Counter)\n",
        "        self.general_top_items = []\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        self.user_item_preferences = defaultdict(Counter)\n",
        "\n",
        "    def prepare_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "        if df.empty:\n",
        "            return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "        item_stats = df.groupby('goodsName').agg(\n",
        "            total_purchases=('goodsName', 'count'),\n",
        "            unique_checks=('timeCheck', 'nunique'),\n",
        "            unique_customers=('customerId', 'nunique')\n",
        "        )\n",
        "\n",
        "        adaptive_min_samples = max(1, int(len(df) * 0.001))\n",
        "        adaptive_min_checks = max(1, int(df['timeCheck'].nunique() * 0.01))\n",
        "\n",
        "        valid_items = item_stats[\n",
        "            (item_stats['total_purchases'] >= max(self.min_samples, adaptive_min_samples)) &\n",
        "            (item_stats['unique_checks'] >= max(self.min_unique_checks, adaptive_min_checks))\n",
        "        ].index.tolist()\n",
        "\n",
        "        if not valid_items:\n",
        "            return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "        basket_df = df[df['goodsName'].isin(valid_items)] \\\n",
        "            .groupby(['customerId', 'timeCheck', 'pointName', 'day_of_week', 'month', 'time_of_day'])['goodsName'] \\\n",
        "            .apply(list).reset_index(name='basket')\n",
        "\n",
        "        for _, row in basket_df.iterrows():\n",
        "            self.user_item_preferences[row['customerId']].update(row['basket'])\n",
        "\n",
        "        self.item_encoder.fit(valid_items)\n",
        "        y = basket_df['basket'].apply(lambda x: [i for i in x if i in valid_items])\n",
        "        valid_indices = y.apply(len) > 0\n",
        "        basket_df = basket_df[valid_indices]\n",
        "        y = y[valid_indices]\n",
        "\n",
        "        self.mlb.fit([self.item_encoder.classes_])\n",
        "        y_encoded = self.mlb.transform(y)\n",
        "\n",
        "        X = basket_df[['customerId', 'pointName', 'day_of_week', 'month', 'time_of_day']]\n",
        "\n",
        "        return X, pd.DataFrame(y_encoded, columns=self.item_encoder.classes_)\n",
        "\n",
        "    def train(self, df: pd.DataFrame) -> None:\n",
        "        for _, row in df.iterrows():\n",
        "            key = (row['pointName'], row['day_of_week'], row['time_of_day'])\n",
        "            self.context_recommendations[key][row['goodsName']] += 1\n",
        "\n",
        "        item_stats = df.groupby('goodsName').agg(\n",
        "            total_purchases=('goodsName', 'count'),\n",
        "            unique_checks=('timeCheck', 'nunique')\n",
        "        )\n",
        "\n",
        "        adaptive_min_checks = max(1, int(df['timeCheck'].nunique() * 0.01))\n",
        "        cyclic_items = item_stats[item_stats['unique_checks'] >= adaptive_min_checks].index\n",
        "\n",
        "        self.general_top_items = df[df['goodsName'].isin(cyclic_items)]['goodsName'] \\\n",
        "            .value_counts().head(self.top_k*5).index.tolist()\n",
        "\n",
        "        X, y = self.prepare_data(df)\n",
        "\n",
        "        if X.empty or y.empty:\n",
        "            return\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('preprocessor', self.feature_encoder),\n",
        "            ('classifier', OneVsRestClassifier(\n",
        "                CatBoostClassifier(\n",
        "                    iterations=200,\n",
        "                    depth=6,\n",
        "                    learning_rate=0.1,\n",
        "                    loss_function='MultiClass',\n",
        "                    verbose=False,\n",
        "                    random_state=42,\n",
        "                    thread_count=-1\n",
        "                ), n_jobs=-1\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "        pipeline.fit(X, y)\n",
        "        self.model = pipeline\n",
        "\n",
        "    def predict(self, context: Dict) -> List[str]:\n",
        "        try:\n",
        "            customer_id = context['customerId']\n",
        "\n",
        "            # Personalized recommendations with diversity\n",
        "            if customer_id in self.user_item_preferences:\n",
        "                user_items = self.user_item_preferences[customer_id]\n",
        "                user_top = [item for item, _ in user_items.most_common(self.top_k*3)]\n",
        "\n",
        "                if len(user_top) >= 3:\n",
        "                    # Select 1-2 top items and 1-2 less frequent\n",
        "                    selected = user_top[:1]\n",
        "                    diverse_pool = [i for i in user_top if i not in selected]\n",
        "                    if diverse_pool:\n",
        "                        selected += random.sample(diverse_pool, min(2, len(diverse_pool)))\n",
        "                    return selected[:self.top_k]\n",
        "\n",
        "            # Model predictions with diversity\n",
        "            if self.model is not None:\n",
        "                X_pred = pd.DataFrame([{\n",
        "                    'customerId': context['customerId'],\n",
        "                    'pointName': context['pointName'],\n",
        "                    'day_of_week': context['day_of_week'],\n",
        "                    'month': context['month'],\n",
        "                    'time_of_day': context['time_of_day']\n",
        "                }])\n",
        "\n",
        "                if hasattr(self.model, 'predict_proba'):\n",
        "                    probs = self.model.predict_proba(X_pred)\n",
        "                    scores = np.array([p[:, 1] if p.ndim > 1 else p for p in probs]).squeeze()\n",
        "                else:\n",
        "                    scores = self.model.decision_function(X_pred).squeeze()\n",
        "\n",
        "                if scores.ndim > 0:\n",
        "                    top_indices = np.argsort(-scores)[:self.top_k*5]\n",
        "                    candidates = [self.item_encoder.classes_[i] for i in top_indices\n",
        "                                if i < len(self.item_encoder.classes_)]\n",
        "\n",
        "                    if customer_id in self.user_item_preferences:\n",
        "                        user_prefs = self.user_item_preferences[customer_id]\n",
        "                        candidates = sorted(candidates, key=lambda x: -user_prefs.get(x, 0))\n",
        "\n",
        "                    # Enforce diversity in final selection\n",
        "                    if len(candidates) >= 3:\n",
        "                        selected = candidates[:1]\n",
        "                        diverse_pool = [i for i in candidates if i not in selected]\n",
        "                        if diverse_pool:\n",
        "                            selected += random.sample(diverse_pool, min(2, len(diverse_pool)))\n",
        "                        return selected[:self.top_k]\n",
        "\n",
        "            # Fallback with context and diversity\n",
        "            key = (context['pointName'], context['day_of_week'], context['time_of_day'])\n",
        "            items = [item for item, _ in self.context_recommendations.get(key, Counter()).most_common(self.top_k*3)]\n",
        "\n",
        "            if len(items) >= 3:\n",
        "                selected = items[:1]\n",
        "                diverse_pool = [i for i in items if i not in selected]\n",
        "                if diverse_pool:\n",
        "                    selected += random.sample(diverse_pool, min(2, len(diverse_pool)))\n",
        "                return selected[:self.top_k]\n",
        "\n",
        "            return items[:self.top_k] if items else self.general_top_items[:self.top_k]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction error: {str(e)}\", file=sys.stderr)\n",
        "            return self._get_fallback_recommendations(context)\n",
        "\n",
        "    def _get_fallback_recommendations(self, context: Dict) -> List[str]:\n",
        "        key = (context['pointName'], context['day_of_week'], context['time_of_day'])\n",
        "        items = [item for item, _ in self.context_recommendations.get(key, Counter()).most_common(self.top_k)]\n",
        "        return items[:self.top_k] if items else self.general_top_items[:self.top_k]\n",
        "\n"
      ],
      "metadata": {
        "id": "KdBuiHNT9agc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PurchasePredictor:\n",
        "    def __init__(self):\n",
        "        self.time_model = None\n",
        "        self.place_model = None\n",
        "        self.item_predictor = ItemPredictor(\n",
        "            min_cycles=1,\n",
        "            recent_weight=2.0,\n",
        "            diversity_factor=0.3,\n",
        "            popularity_penalty=0.7\n",
        "        )\n",
        "        self.basket_predictor = BasketPredictor(\n",
        "            min_unique_checks=1,\n",
        "            diversity_factor=0.3,\n",
        "            place_diversity=0.3\n",
        "        )\n",
        "        self.last_trained = None\n",
        "        self.general_top_items = []\n",
        "        self.general_common_place = \"\"\n",
        "        self.general_common_hour = None\n",
        "        self.min_samples = 2\n",
        "        self.trained_customers = set()\n",
        "        self.user_time_preferences = defaultdict(list)\n",
        "        self.user_place_preferences = defaultdict(list)\n",
        "        self.user_purchase_hours = defaultdict(list)\n",
        "        self.user_visit_places = defaultdict(list)\n",
        "        self.user_purchase_intervals = defaultdict(list)\n",
        "        self.user_last_purchase = defaultdict(datetime)\n",
        "\n",
        "    def _get_time_of_day(self, hour: int) -> str:\n",
        "        if 5 <= hour < 11: return 'morning'\n",
        "        elif 11 <= hour < 16: return 'afternoon'\n",
        "        elif 16 <= hour < 21: return 'evening'\n",
        "        else: return 'night'\n",
        "\n",
        "    def _analyze_user_behavior(self, df: pd.DataFrame):\n",
        "        for customer_id, group in df.groupby('customerId'):\n",
        "            customer_id = str(customer_id)\n",
        "            self.user_purchase_hours[customer_id] = group['hour'].value_counts().index.tolist()\n",
        "            self.user_visit_places[customer_id] = group['pointName'].value_counts().index.tolist()\n",
        "\n",
        "            if len(group) > 1:\n",
        "                sorted_dates = group['datetime'].sort_values()\n",
        "                intervals = (sorted_dates.diff().dt.total_seconds() / 3600).dropna()\n",
        "                self.user_purchase_intervals[customer_id] = intervals.tolist()\n",
        "\n",
        "            self.user_last_purchase[customer_id] = group['datetime'].max()\n",
        "\n",
        "            if len(group) >= 2:\n",
        "                hour_mode = group['hour'].mode()\n",
        "                if not hour_mode.empty:\n",
        "                    self.user_time_preferences[customer_id] = hour_mode.tolist()\n",
        "\n",
        "            place_mode = group['pointName'].mode()\n",
        "            if not place_mode.empty:\n",
        "                self.user_place_preferences[customer_id] = place_mode.tolist()\n",
        "\n",
        "    def load_and_preprocess(self, json_data: List[Dict]) -> pd.DataFrame:\n",
        "        try:\n",
        "            df = pd.DataFrame(json_data)\n",
        "            required_columns = ['customerId', 'timeCheck', 'pointName', 'goodsName']\n",
        "\n",
        "            for col in required_columns:\n",
        "                if col not in df.columns:\n",
        "                    raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "            df = df.drop_duplicates(subset=required_columns)\n",
        "            df['pointName'] = df['pointName'].str.strip()\n",
        "            df['goodsName'] = df['goodsName'].str.strip()\n",
        "\n",
        "            df['datetime'] = pd.to_datetime(df['timeCheck'])\n",
        "            df['hour'] = df['datetime'].dt.hour\n",
        "            df['day_of_week'] = df['datetime'].dt.dayofweek\n",
        "            df['month'] = df['datetime'].dt.month\n",
        "            df['time_of_day'] = df['hour'].apply(self._get_time_of_day)\n",
        "\n",
        "            df = df.dropna(subset=required_columns)\n",
        "            self._analyze_user_behavior(df)\n",
        "\n",
        "            for _, row in df.iterrows():\n",
        "                self.item_predictor.update_history(\n",
        "                    str(row['customerId']),\n",
        "                    row['goodsName'],\n",
        "                    row['datetime']\n",
        "                )\n",
        "\n",
        "            if not df.empty:\n",
        "                item_stats = df.groupby('goodsName').agg(\n",
        "                    total_purchases=('goodsName', 'count'),\n",
        "                    unique_checks=('timeCheck', 'nunique'),\n",
        "                    unique_customers=('customerId', 'nunique')\n",
        "                )\n",
        "\n",
        "                adaptive_min_checks = max(1, int(df['timeCheck'].nunique() * 0.01))\n",
        "                cyclic_items = item_stats[item_stats['unique_checks'] >= adaptive_min_checks].index\n",
        "\n",
        "                self.general_top_items = df[df['goodsName'].isin(cyclic_items)] \\\n",
        "                    ['goodsName'].value_counts().head(15).index.tolist()\n",
        "                self.general_common_place = df['pointName'].mode()[0] if not df['pointName'].empty else \"\"\n",
        "                self.general_common_hour = df['hour'].mode()[0] if not df['hour'].empty else None\n",
        "\n",
        "            return df.drop(columns=['datetime'])\n",
        "        except Exception as e:\n",
        "            print(f\"Data processing error: {e}\", file=sys.stderr)\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def train_models(self, df: pd.DataFrame) -> None:\n",
        "        if df.empty:\n",
        "            print(\"No data for training\", file=sys.stderr)\n",
        "            return\n",
        "\n",
        "        print(\"\\nData analysis before training:\")\n",
        "        print(\"Unique customers:\", df['customerId'].nunique())\n",
        "        print(\"Unique places:\", df['pointName'].nunique())\n",
        "        print(\"Unique hours:\", df['hour'].nunique())\n",
        "        print(\"Average places per customer:\",\n",
        "              df.groupby('customerId')['pointName'].nunique().mean())\n",
        "\n",
        "        item_stats = df.groupby('goodsName').agg(\n",
        "            total_purchases=('goodsName', 'count'),\n",
        "            unique_checks=('timeCheck', 'nunique'),\n",
        "            unique_customers=('customerId', 'nunique')\n",
        "        )\n",
        "\n",
        "        adaptive_min_samples = max(1, int(len(df) * 0.001))\n",
        "        adaptive_min_checks = max(1, int(df['timeCheck'].nunique() * 0.01))\n",
        "\n",
        "        valid_items = item_stats[\n",
        "            (item_stats['total_purchases'] >= max(self.min_samples, adaptive_min_samples)) &\n",
        "            (item_stats['unique_checks'] >= adaptive_min_checks)\n",
        "        ].index\n",
        "\n",
        "        df_filtered = df[df['goodsName'].isin(valid_items)]\n",
        "\n",
        "        if df_filtered.empty:\n",
        "            print(\"Warning: No items with cyclic purchases\", file=sys.stderr)\n",
        "            return\n",
        "\n",
        "        self.trained_customers = set(df_filtered['customerId'].astype(str).unique())\n",
        "\n",
        "        # Time model\n",
        "        X_time = df_filtered[['customerId', 'day_of_week', 'month', 'time_of_day']]\n",
        "        y_time = df_filtered['hour']\n",
        "\n",
        "        if not X_time.empty and y_time.nunique() > 1:\n",
        "            self.time_model = Pipeline([\n",
        "                ('preprocessor', ColumnTransformer(\n",
        "                    transformers=[\n",
        "                        ('customer', OneHotEncoder(handle_unknown='ignore'), ['customerId']),\n",
        "                        ('time', OneHotEncoder(handle_unknown='ignore'),\n",
        "                         ['day_of_week', 'month', 'time_of_day'])\n",
        "                    ]\n",
        "                )),\n",
        "                ('regressor', RandomForestRegressor(\n",
        "                    n_estimators=100,\n",
        "                    random_state=42,\n",
        "                    n_jobs=-1,\n",
        "                    min_samples_leaf=3\n",
        "                ))\n",
        "            ])\n",
        "            self.time_model.fit(X_time, y_time)\n",
        "            print(\"\\nTime model trained with user preferences\")\n",
        "\n",
        "        # Place model with LGBM\n",
        "        X_place = df_filtered[['customerId', 'day_of_week', 'month', 'time_of_day', 'hour']]\n",
        "        y_place = df_filtered['pointName']\n",
        "\n",
        "        if not X_place.empty and y_place.nunique() > 1:\n",
        "            self.place_model = Pipeline([\n",
        "                ('preprocessor', ColumnTransformer(\n",
        "                    transformers=[\n",
        "                        ('customer', OneHotEncoder(handle_unknown='ignore'), ['customerId']),\n",
        "                        ('time', OneHotEncoder(handle_unknown='ignore'),\n",
        "                         ['day_of_week', 'month', 'time_of_day']),\n",
        "                        ('hour', OneHotEncoder(handle_unknown='ignore'), ['hour'])\n",
        "                    ]\n",
        "                )),\n",
        "                ('classifier', LGBMClassifier(\n",
        "                    n_estimators=100,\n",
        "                    random_state=42,\n",
        "                    n_jobs=-1,\n",
        "                    class_weight='balanced',\n",
        "                    min_child_samples=3\n",
        "                ))\n",
        "            ])\n",
        "            self.place_model.fit(X_place, y_place)\n",
        "            print(\"Place model trained with additional features\")\n",
        "\n",
        "        # Train basket model\n",
        "        print(\"\\nTraining basket model...\")\n",
        "        self.basket_predictor.train(df_filtered)\n",
        "\n",
        "        self.last_trained = datetime.now()\n",
        "        print(\"\\nTraining completed\")\n",
        "\n",
        "    def predict_for_customer(self, customer_id: Union[str, int],\n",
        "                           day_of_week: Optional[int] = None,\n",
        "                           month: Optional[int] = None) -> Dict[str, Any]:\n",
        "        customer_id = str(customer_id)\n",
        "        current_date = datetime.now()\n",
        "        last_purchase = self.user_last_purchase.get(customer_id)\n",
        "\n",
        "        if day_of_week is None:\n",
        "            day_of_week = current_date.weekday()\n",
        "        if month is None:\n",
        "            month = current_date.month\n",
        "\n",
        "        current_hour = current_date.hour\n",
        "        time_of_day = self._get_time_of_day(current_hour)\n",
        "\n",
        "        # User status detection\n",
        "        is_new_user = customer_id not in self.trained_customers\n",
        "        is_inactive = False\n",
        "\n",
        "        if last_purchase:\n",
        "            days_inactive = (current_date - last_purchase).days\n",
        "            is_inactive = days_inactive > 30\n",
        "\n",
        "        # Get user preferences\n",
        "        user_hours = self.user_purchase_hours.get(customer_id, [])\n",
        "        user_places = self.user_visit_places.get(customer_id, [])\n",
        "        user_intervals = self.user_purchase_intervals.get(customer_id, [])\n",
        "\n",
        "        # Time prediction with diversity\n",
        "        predicted_hour = user_hours[0] if user_hours else self.general_common_hour or current_hour\n",
        "\n",
        "        if not is_new_user and self.time_model:\n",
        "            try:\n",
        "                time_input = pd.DataFrame([{\n",
        "                    'customerId': customer_id,\n",
        "                    'day_of_week': day_of_week,\n",
        "                    'month': month,\n",
        "                    'time_of_day': time_of_day\n",
        "                }])\n",
        "\n",
        "                model_pred = self.time_model.predict(time_input)[0]\n",
        "\n",
        "                if user_hours:\n",
        "                    user_avg = np.mean(user_hours[:3])\n",
        "                    predicted_hour = int(round(model_pred * 0.6 + user_avg * 0.4))\n",
        "                else:\n",
        "                    predicted_hour = int(round(model_pred))\n",
        "\n",
        "                predicted_hour = max(0, min(23, predicted_hour))\n",
        "\n",
        "                if user_intervals and not is_inactive:\n",
        "                    avg_interval = np.mean(user_intervals)\n",
        "                    if avg_interval > 0:\n",
        "                        expected_hour = last_purchase.hour + (avg_interval % 24)\n",
        "                        predicted_hour = int(round(predicted_hour * 0.7 + expected_hour * 0.3))\n",
        "            except Exception as e:\n",
        "                print(f\"Time prediction error: {e}\", file=sys.stderr)\n",
        "\n",
        "        # Place prediction with enforced diversity\n",
        "        predicted_place = user_places[0] if user_places else self.general_common_place\n",
        "\n",
        "        if not is_new_user and self.place_model:\n",
        "            try:\n",
        "                place_input = pd.DataFrame([{\n",
        "                    'customerId': customer_id,\n",
        "                    'day_of_week': day_of_week,\n",
        "                    'month': month,\n",
        "                    'time_of_day': time_of_day,\n",
        "                    'hour': predicted_hour\n",
        "                }])\n",
        "\n",
        "                if len(user_places) >= 2:\n",
        "                    place_probs = self.place_model.predict_proba(place_input)\n",
        "                    top_places = self.place_model.classes_[np.argsort(-place_probs[0])][:5]\n",
        "\n",
        "                    # Add randomness to place selection\n",
        "                    if random.random() < self.basket_predictor.place_diversity:\n",
        "                        predicted_place = random.choice(top_places[:3])\n",
        "                    else:\n",
        "                        for place in top_places:\n",
        "                            if place in user_places[:3]:\n",
        "                                predicted_place = place\n",
        "                                break\n",
        "                        else:\n",
        "                            predicted_place = top_places[0]\n",
        "                else:\n",
        "                    predicted_place = self.place_model.predict(place_input)[0]\n",
        "            except Exception as e:\n",
        "                print(f\"Place prediction error: {e}\", file=sys.stderr)\n",
        "\n",
        "        # Prepare basket context\n",
        "        basket_context = {\n",
        "            'customerId': customer_id,\n",
        "            'pointName': predicted_place,\n",
        "            'day_of_week': day_of_week,\n",
        "            'month': month,\n",
        "            'time_of_day': time_of_day,\n",
        "            'is_new_user': is_new_user or is_inactive\n",
        "        }\n",
        "\n",
        "        # Get basket predictions\n",
        "        top_items = self.basket_predictor.predict(basket_context)[:3]\n",
        "\n",
        "        # For new/inactive users, add more diversity\n",
        "        if is_new_user or is_inactive:\n",
        "            if len(top_items) > 1 and random.random() < 0.5:\n",
        "                top_items[-1] = random.choice(self.general_top_items[:20])\n",
        "\n",
        "        # Generate message\n",
        "        message = None\n",
        "        if is_new_user:\n",
        "            purchase_count = len(self.item_predictor.user_history.get(customer_id, []))\n",
        "            if purchase_count < 2:\n",
        "                message = f\"Make {2 - purchase_count} more purchases to get personalized recommendations\"\n",
        "        elif is_inactive:\n",
        "            days = (current_date - last_purchase).days\n",
        "            message = f\"We've missed you! It's been {days} days since your last purchase\"\n",
        "\n",
        "        # Create time window with variation\n",
        "        window_size = random.choice([2, 3, 4])\n",
        "        time_window_start = predicted_hour\n",
        "        time_window_end = (predicted_hour + window_size) % 24\n",
        "        time_window = f\"{time_window_start:02d}:00-{time_window_end:02d}:00\"\n",
        "\n",
        "        return {\n",
        "            'customerId': customer_id,\n",
        "            'top_items': top_items,\n",
        "            'predicted_time': time_window,\n",
        "            'predicted_place': predicted_place,\n",
        "            'is_new_user': is_new_user,\n",
        "            'is_inactive': is_inactive,\n",
        "            'message': message\n",
        "        }\n",
        "\n",
        "    def save_model(self, path: str) -> None:\n",
        "        model_state = {\n",
        "            'time_model': self.time_model,\n",
        "            'place_model': self.place_model,\n",
        "            'general_top_items': self.general_top_items,\n",
        "            'general_common_place': self.general_common_place,\n",
        "            'general_common_hour': self.general_common_hour,\n",
        "            'last_trained': self.last_trained,\n",
        "            'min_samples': self.min_samples,\n",
        "            'trained_customers': list(self.trained_customers),\n",
        "            'basket_predictor': self.basket_predictor,\n",
        "            'item_predictor': {\n",
        "                'user_history': {\n",
        "                    user_id: [(item, date.isoformat()) for item, date in entries]\n",
        "                    for user_id, entries in self.item_predictor.user_history.items()\n",
        "                },\n",
        "                'global_item_freq': dict(self.item_predictor.global_item_freq),\n",
        "                'global_top_items': self.item_predictor.global_top_items,\n",
        "                'update_counter': self.item_predictor.update_counter,\n",
        "                'params': {\n",
        "                    'min_cycles': self.item_predictor.min_cycles,\n",
        "                    'period_days': self.item_predictor.period_days,\n",
        "                    'top_k': self.item_predictor.top_k,\n",
        "                    'recent_weight': self.item_predictor.recent_weight,\n",
        "                    'decay_factor': self.item_predictor.decay_factor,\n",
        "                    'diversity_factor': self.item_predictor.diversity_factor,\n",
        "                    'popularity_penalty': self.item_predictor.popularity_penalty\n",
        "                }\n",
        "            },\n",
        "            'user_behavior': {\n",
        "                'time_preferences': dict(self.user_time_preferences),\n",
        "                'place_preferences': dict(self.user_place_preferences),\n",
        "                'purchase_hours': dict(self.user_purchase_hours),\n",
        "                'visit_places': dict(self.user_visit_places),\n",
        "                'purchase_intervals': dict(self.user_purchase_intervals),\n",
        "                'last_purchase': {k: v.isoformat() for k, v in self.user_last_purchase.items()}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        joblib.dump(model_state, path)\n",
        "        print(f\"Model successfully saved to {path}\")\n",
        "\n",
        "    def load_model(self, path: str) -> None:\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Model file {path} not found\")\n",
        "\n",
        "        model_state = joblib.load(path)\n",
        "\n",
        "        self.time_model = model_state.get('time_model')\n",
        "        self.place_model = model_state.get('place_model')\n",
        "        self.general_top_items = model_state.get('general_top_items', [])\n",
        "        self.general_common_place = model_state.get('general_common_place', \"\")\n",
        "        self.general_common_hour = model_state.get('general_common_hour')\n",
        "        self.last_trained = model_state.get('last_trained')\n",
        "        self.min_samples = model_state.get('min_samples', 2)\n",
        "        self.trained_customers = set(model_state.get('trained_customers', []))\n",
        "        self.basket_predictor = model_state.get('basket_predictor', BasketPredictor())\n",
        "\n",
        "        item_data = model_state.get('item_predictor', {})\n",
        "        params = item_data.get('params', {})\n",
        "        self.item_predictor = ItemPredictor(\n",
        "            min_cycles=params.get('min_cycles', 1),\n",
        "            period_days=params.get('period_days', 30),\n",
        "            top_k=params.get('top_k', 3),\n",
        "            recent_weight=params.get('recent_weight', 2.0),\n",
        "            decay_factor=params.get('decay_factor', 0.95),\n",
        "            diversity_factor=params.get('diversity_factor', 0.3),\n",
        "            popularity_penalty=params.get('popularity_penalty', 0.7)\n",
        "        )\n",
        "\n",
        "        self.item_predictor.user_history = defaultdict(list)\n",
        "        for user_id, entries in item_data.get('user_history', {}).items():\n",
        "            for item, date_str in entries:\n",
        "                self.item_predictor.user_history[user_id].append(\n",
        "                    (item, datetime.fromisoformat(date_str)))\n",
        "\n",
        "        self.item_predictor.global_item_freq = Counter(item_data.get('global_item_freq', {}))\n",
        "        self.item_predictor.global_top_items = item_data.get('global_top_items', [])\n",
        "        self.item_predictor.update_counter = item_data.get('update_counter', 0)\n",
        "\n",
        "        behavior_data = model_state.get('user_behavior', {})\n",
        "        self.user_time_preferences = defaultdict(list, behavior_data.get('time_preferences', {}))\n",
        "        self.user_place_preferences = defaultdict(list, behavior_data.get('place_preferences', {}))\n",
        "        self.user_purchase_hours = defaultdict(list, behavior_data.get('purchase_hours', {}))\n",
        "        self.user_visit_places = defaultdict(list, behavior_data.get('visit_places', {}))\n",
        "        self.user_purchase_intervals = defaultdict(list, behavior_data.get('purchase_intervals', {}))\n",
        "        self.user_last_purchase = defaultdict(datetime)\n",
        "        for user_id, date_str in behavior_data.get('last_purchase', {}).items():\n",
        "            self.user_last_purchase[user_id] = datetime.fromisoformat(date_str)\n",
        "\n",
        "        print(f\"Model successfully loaded from {path}\")"
      ],
      "metadata": {
        "id": "9vp3f9W1Zcal"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_workflow(input_json_path: str, output_json_path: Optional[str] = None) -> List[Dict]:\n",
        "    try:\n",
        "        with open(input_json_path, 'r', encoding='utf-8') as f:\n",
        "            json_data = json.load(f)\n",
        "        print(f\"Successfully loaded {len(json_data)} receipts\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading JSON: {e}\", file=sys.stderr)\n",
        "        return []\n",
        "\n",
        "    predictor = PurchasePredictor()\n",
        "    try:\n",
        "        df = predictor.load_and_preprocess(json_data)\n",
        "        if df.empty:\n",
        "            print(\"Error: No valid data\", file=sys.stderr)\n",
        "            return []\n",
        "\n",
        "        predictor.train_models(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Training error: {e}\", file=sys.stderr)\n",
        "        return []\n",
        "\n",
        "    predictions = []\n",
        "    unique_customers = df['customerId'].astype(str).unique() if not df.empty else []\n",
        "    print(f\"\\nFound {len(unique_customers)} customers\")\n",
        "\n",
        "    for customer_id in unique_customers:\n",
        "        try:\n",
        "            prediction = predictor.predict_for_customer(customer_id)\n",
        "            predictions.append(prediction)\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction error for {customer_id}: {e}\", file=sys.stderr)\n",
        "\n",
        "    # Analyze prediction diversity\n",
        "    unique_time_place = len(set((p['predicted_time'], p['predicted_place']) for p in predictions))\n",
        "    all_items = [item for p in predictions for item in p['top_items']]\n",
        "    unique_items = len(set(all_items))\n",
        "    item_counts = Counter(all_items)\n",
        "\n",
        "    print(f\"\\nPrediction diversity analysis:\")\n",
        "    print(f\"- Unique time/place combinations: {unique_time_place} of {len(predictions)}\")\n",
        "    print(f\"- Unique recommended items: {unique_items}\")\n",
        "    print(f\"- Average recommendations per item: {len(predictions)*3/unique_items:.1f}\")\n",
        "    print(f\"- Most recommended items:\")\n",
        "    for item, count in item_counts.most_common(5):\n",
        "        print(f\"  {item}: {count} times ({(count/len(predictions)*100):.1f}%)\")\n",
        "\n",
        "    if output_json_path and predictions:\n",
        "        try:\n",
        "            with open(output_json_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"\\nPredictions saved to {output_json_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving predictions: {e}\", file=sys.stderr)\n",
        "\n",
        "    try:\n",
        "        model_path = os.path.join(\n",
        "            os.path.dirname(input_json_path) or os.getcwd(),\n",
        "            'purchase_predictor_model.joblib'\n",
        "        )\n",
        "        predictor.save_model(model_path)\n",
        "        print(f\"Model saved to {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model: {e}\", file=sys.stderr)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_path = \"/content/drive/MyDrive/ai.json\"  # Update with your path\n",
        "    output_path = \"/content/drive/MyDrive/output.json\"  # Update with your path\n",
        "\n",
        "    predictions = main_workflow(\n",
        "        input_json_path=input_path,\n",
        "        output_json_path=output_path\n",
        "    )\n",
        "\n",
        "    if predictions:\n",
        "        print(\"\\nPrediction examples:\")\n",
        "        for i, pred in enumerate(predictions[:5]):\n",
        "            print(f\"\\nPrediction #{i+1} for customer {pred['customerId']}:\")\n",
        "            print(f\"- Top items: {', '.join(pred['top_items'])}\")\n",
        "            print(f\"- Time window: {pred['predicted_time']}\")\n",
        "            print(f\"- Place: {pred['predicted_place']}\")\n",
        "            if pred.get('message'):\n",
        "                print(f\"- Message: {pred['message']}\")\n",
        "            print(f\"- Status: {'New' if pred['is_new_user'] else 'Inactive' if pred['is_inactive'] else 'Active'}\")"
      ],
      "metadata": {
        "id": "2cv6Z2M7aoQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f728105-8820-4d8e-ef7d-a40bb15862f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 40000 receipts\n",
            "\n",
            "Data analysis before training:\n",
            "Unique customers: 6094\n",
            "Unique places: 67\n",
            "Unique hours: 16\n",
            "Average places per customer: 1.039875287167706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import joblib\n",
        "\n",
        "# Загружаем файл модели\n",
        "uploaded = files.upload()\n",
        "model_path = next(iter(uploaded.keys()))  # Получаем имя файла\n",
        "\n",
        "# Загружаем модель\n",
        "try:\n",
        "    predictor = PurchasePredictor()\n",
        "    predictor.load_model(model_path)\n",
        "    print(\"✅ Модель успешно загружена!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Ошибка загрузки модели: {e}\")"
      ],
      "metadata": {
        "id": "uUNdKOC_bjdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем JSON с новыми чеками\n",
        "new_data_upload = files.upload()\n",
        "new_data_path = next(iter(new_data_upload.keys()))\n",
        "\n",
        "# Читаем данные\n",
        "with open(new_data_path, 'r', encoding='utf-8') as f:\n",
        "    new_checks = json.load(f)\n",
        "\n",
        "# Предобработка (как в load_and_preprocess)\n",
        "df_new = predictor.load_and_preprocess(new_checks)"
      ],
      "metadata": {
        "id": "TAuV9e_Sbkqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = {}\n",
        "for user_id in df_new['customerId'].unique():\n",
        "    try:\n",
        "        # Явно конвертируем user_id в строку\n",
        "        user_id_str = str(user_id)\n",
        "        pred = predictor.predict_for_customer(user_id_str)\n",
        "\n",
        "        # Конвертируем numpy.str_ в обычные строки\n",
        "        pred['top_items'] = [str(item) for item in pred['top_items']]\n",
        "\n",
        "        predictions[user_id_str] = pred\n",
        "        print(f\"Пользователь {user_id_str}: {pred['top_items']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка для {user_id}: {e}\")\n",
        "\n",
        "# Сохраняем с явным преобразованием типов\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(predictions, f, indent=2, ensure_ascii=False, default=str)"
      ],
      "metadata": {
        "id": "nF-FSpFJbrse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Таблица с топ-рекомендациями\n",
        "df_results = pd.DataFrame.from_dict(predictions, orient='index')\n",
        "print(\"Топ-рекомендации:\")\n",
        "display(df_results[['top_items', 'predicted_place']].head(10))\n",
        "\n",
        "# График распределения рекомендуемых товаров\n",
        "all_items = [item for pred in predictions.values() for item in pred['top_items']]\n",
        "pd.Series(all_items).value_counts().head(15).plot(kind='barh', title=\"Самые частые рекомендации\");"
      ],
      "metadata": {
        "id": "o40FIIm6buUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Собираем фактические покупки\n",
        "actual_purchases = {}\n",
        "for _, row in df_new.iterrows():\n",
        "    user_id = str(row['customerId'])\n",
        "    if user_id not in actual_purchases:\n",
        "        actual_purchases[user_id] = []\n",
        "    actual_purchases[user_id].append(row['goodsName'])\n",
        "\n",
        "# Сравниваем\n",
        "for user_id, pred in predictions.items():\n",
        "    print(f\"\\nПользователь {user_id}:\")\n",
        "    print(\"Рекомендовано:\", pred['top_items'])\n",
        "    print(\"Купил:\", actual_purchases.get(user_id, \"Нет данных\"))"
      ],
      "metadata": {
        "id": "k23cx5Prb468"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1MqESltQkL78Ix2nf2sW14jlx766nT-DE",
      "authorship_tag": "ABX9TyMN0Amhj8zaWA8I3xGSU/wl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}